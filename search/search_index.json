{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Home","text":""},{"location":"#template-de-entrega","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Theo Camuri Gaspar Grupo - Masked Penguins:</li> </ol>"},{"location":"#entregas","title":"Entregas","text":""},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"K-Means/main/","title":"K-Means","text":""},{"location":"K-Means/main/#agrupamento-de-estresse-academico-com-k-means","title":"Agrupamento de Estresse Acad\u00eamico com K-Means","text":""},{"location":"K-Means/main/#exploracao-dos-dados","title":"Explora\u00e7\u00e3o dos Dados","text":"<p>A base <code>StressExp.csv</code> cont\u00e9m 280 registros e 9 colunas. As vari\u00e1veis s\u00e3o relacionadas ao perfil acad\u00eamico dos alunos, press\u00f5es percebidas, ambiente de estudo e h\u00e1bitos.</p> <ul> <li>AcademicStage: N\u00edvel acad\u00eamico do respondente.  </li> <li>PeerPressure: Press\u00e3o dos colegas (escala 1\u20135).  </li> <li>HomePressure: Press\u00e3o da fam\u00edlia (escala 1\u20135).  </li> <li>StudyEnv: Ambiente de estudo (Peaceful, Noisy, Disrupted).  </li> <li>Strategy: Estrat\u00e9gias de enfrentamento.  </li> <li>BadHabits: Maus h\u00e1bitos (Sim/N\u00e3o).  </li> <li>AcademicComp: Competi\u00e7\u00e3o acad\u00eamica (escala 1\u20135).  </li> <li>Stress: N\u00edvel de estresse (1\u20135). Usado apenas como valida\u00e7\u00e3o externa.  </li> </ul> AcademicStage PeerPressure HomePressure StudyEnv Strategy BadHabits AcademicComp Stress undergraduate 4 5 Noisy Analyze the situation and handle it with intellect No 3 5 undergraduate 3 4 Peaceful Analyze the situation and handle it with intellect No 3 3 undergraduate 1 1 Peaceful Social support (friends, family) No 2 4 undergraduate 3 2 Peaceful Analyze the situation and handle it with intellect No 4 3 undergraduate 3 3 Peaceful Analyze the situation and handle it with intellect No 4 5"},{"location":"K-Means/main/#pre-processamento","title":"Pr\u00e9-processamento","text":"<ul> <li>A coluna Timestamp foi removida por n\u00e3o agregar informa\u00e7\u00e3o.  </li> <li>A vari\u00e1vel StudyEnv apresentava 1 valor nulo, que foi preenchido com a moda (Peaceful).  </li> <li>Vari\u00e1veis categ\u00f3ricas (AcademicStage, StudyEnv, Strategy, BadHabits) foram convertidas em valores num\u00e9ricos via Label Encoding.  </li> <li>A vari\u00e1vel Stress foi removida das features para o K-Means, sendo utilizada apenas na avalia\u00e7\u00e3o posterior.  </li> <li>As features num\u00e9ricas foram padronizadas com <code>StandardScaler</code> para garantir que todas tenham a mesma escala.  </li> </ul>"},{"location":"K-Means/main/#clustering-k-means","title":"Clustering K-Means","text":"<p>O modelo K-Means foi configurado com: - k = 5 clusters (escolhido por corresponder \u00e0 escala de estresse 1\u20135). - Inicializa\u00e7\u00e3o: <code>k-means++</code>. - M\u00e1ximo de 100 itera\u00e7\u00f5es, <code>random_state=42</code>, <code>n_init=10</code>.  </p>"},{"location":"K-Means/main/#resultados-do-treinamento","title":"Resultados do Treinamento","text":"<ul> <li>In\u00e9rcia (WCSS): 1218.72  </li> <li>Silhouette Score: 0.19 \u2192 Indica que os clusters est\u00e3o pouco separados e h\u00e1 sobreposi\u00e7\u00e3o entre grupos.  </li> </ul>"},{"location":"K-Means/main/#visualizacao-pca-2d","title":"Visualiza\u00e7\u00e3o (PCA 2D)","text":"<p>Os dados foram reduzidos para 2 dimens\u00f5es com PCA apenas para visualiza\u00e7\u00e3o:  </p> K-Meanscode 2025-12-05T14:06:23.747512 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.cluster import KMeans\nimport pandas as pd\n\n\nplt.figure(figsize=(12, 10))\n\n# Preprocess the data\ndef preprocess(df: pd.DataFrame) -&gt; pd.DataFrame:\n    # remocao da coluna Timestamp\n    df = df.drop(columns=['Timestamp'])\n\n    # Tratamento de missing values\n    ## 'Study Environment' tem 1 valor ausente -&gt; preenchid com a moda (valor mais frequente)\n    df['StudyEnv'].fillna(df['StudyEnv'].mode()[0], inplace=True)\n\n    #conversao de variaveis categoricas\n    label_encoder = LabelEncoder()\n    df['AcademicStage'] = label_encoder.fit_transform(df['AcademicStage'])\n    df['StudyEnv'] = label_encoder.fit_transform(df['StudyEnv'])\n    df['Strategy'] = label_encoder.fit_transform(df['Strategy'])\n    df['BadHabits'] = label_encoder.fit_transform(df['BadHabits'])\n\n    # Selecao de features\n    features = [\n        'AcademicStage',                       \n        'PeerPressure',                       \n        'HomePressure',    \n        'StudyEnv',                            \n        'Strategy',                      \n        'BadHabits',\n        'AcademicComp' \n    ]\n\n    return df[features]\n\n# Carregar base\ndf = pd.read_csv('https://raw.githubusercontent.com/tigasparzin/Machine-Learning/refs/heads/main/data/StressExp.csv')\n\n\nX = preprocess(df)\n\n#run Kmeans\nkmeans = KMeans(n_clusters=5, init='k-means++', max_iter=100, random_state=42)\nlabels = kmeans.fit_predict(X)\n\n#Plot\nplt.scatter(X.iloc[:, 0], X.iloc[:, 1], c=labels, cmap='viridis', s=50)\ncent = kmeans.cluster_centers_\nplt.scatter(cent[:, 0], cent[:, 1], c='red', marker='*', s=200, label='Centroids')\n\n\n\nplt.title('K-Means Clustering Results')\nplt.xlabel('Feature 1')\nplt.ylabel('Feature 2')\nplt.legend()\n\n# # Print centroids and inertia\n# print(\"Final centroids:\", kmeans.cluster_centers_)\n# print(\"Inertia (WCSS):\", kmeans.inertia_)\n\n# # Display the plot\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"K-Means/main/#avaliacao-dos-clusters","title":"Avalia\u00e7\u00e3o dos Clusters","text":"<p>A vari\u00e1vel <code>Stress</code> foi usada para verificar como os clusters se alinham com os n\u00edveis reais de estresse.  </p> <p>Tabela cruzada (Stress x Cluster):</p> Stress Cluster 0 Cluster 1 Cluster 2 Cluster 3 Cluster 4 1 13 6 9 7 21 2 11 7 19 5 14 3 3 26 8 15 4 4 3 33 8 11 1 5 9 30 3 13 1 <p>Observa-se que os clusters n\u00e3o correspondem diretamente aos n\u00edveis de estresse, com forte sobreposi\u00e7\u00e3o entre as classes.  </p>"},{"location":"K-Means/main/#conclusao","title":"Conclus\u00e3o","text":"<ul> <li>O K-Means n\u00e3o conseguiu separar claramente os grupos de alunos de acordo com o n\u00edvel de estresse.  </li> <li>O Silhouette Score baixo (0.19) confirma que os clusters s\u00e3o pouco distintos.  </li> <li>Cada cluster mistura diferentes valores de estresse, mostrando que o algoritmo est\u00e1 agrupando mais por perfil geral (est\u00e1gio acad\u00eamico, h\u00e1bitos, ambiente) do que pelo n\u00edvel de estresse em si.  </li> <li>A an\u00e1lise \u00e9 v\u00e1lida para identificar padr\u00f5es de perfis semelhantes, mas n\u00e3o substitui modelos supervisionados como o KNN.  </li> </ul>"},{"location":"K-Means/main/#recomendacoes","title":"Recomenda\u00e7\u00f5es","text":"<ul> <li>Testar diferentes valores de k (m\u00e9todo do cotovelo, silhouette).  </li> <li>Normalizar e/ou reduzir dimensionalidade antes do clustering (ex.: PCA completo).  </li> <li>Usar <code>Stress</code> apenas como valida\u00e7\u00e3o externa, n\u00e3o como feature no clustering.  </li> <li>Considerar outras t\u00e9cnicas de clusteriza\u00e7\u00e3o (ex.: DBSCAN, Agglomerative Clustering) para compara\u00e7\u00e3o.  </li> </ul>"},{"location":"KNN/main/","title":"KNN","text":""},{"location":"KNN/main/#classificacao-de-estresse-academico-com-knn","title":"Classifica\u00e7\u00e3o de Estresse Acad\u00eamico com KNN","text":""},{"location":"KNN/main/#exploracao-dos-dados","title":"Explora\u00e7\u00e3o dos Dados","text":"<p>A base possui 280 registros e 9 colunas.</p> <p>Est\u00e1gio acad\u00eamico: Refere-se ao n\u00edvel acad\u00eamico do respondente (gradua\u00e7\u00e3o, ensino m\u00e9dio, p\u00f3s-gradua\u00e7\u00e3o).</p> <p>Press\u00e3o dos colegas: O quanto o aluno se sente pressionado pelos colegas em uma escala de 1 a 5.</p> <p>Press\u00e3o acad\u00eamica da fam\u00edlia: O quanto o aluno se sente pressionado pela fam\u00edlia em uma escala de 1 a 5.</p> <p>Ambiente de estudo: Como o aluno classifica o ambiente onde estuda (categorias como Peaceful, Noisy, Disrupted).</p> <p>Estrat\u00e9gia de enfrentamento: Como o aluno enfrenta o estresse (ex.: Analisar a situa\u00e7\u00e3o com intelig\u00eancia, Colapso emocional, Apoio de amigos/fam\u00edlia).</p> <p>Maus h\u00e1bitos: Indica se o respondente possui h\u00e1bitos nocivos, como fumar ou beber (Sim/N\u00e3o/Prefiro n\u00e3o responder).</p> <p>Competi\u00e7\u00e3o acad\u00eamica: Grau de competi\u00e7\u00e3o acad\u00eamica percebida (escala de 1 a 5).</p> <p>\u00cdndice de estresse: N\u00edvel de estresse acad\u00eamico (escala de 1 a 5).</p> AcademicStage PeerPressure HomePressure StudyEnv Strategy BadHabits AcademicComp Stress undergraduate 4 5 Noisy Analyze the situation and handle it with intellect No 3 5 undergraduate 3 4 Peaceful Analyze the situation and handle it with intellect No 3 3 undergraduate 1 1 Peaceful Social support (friends, family) No 2 4 undergraduate 3 2 Peaceful Analyze the situation and handle it with intellect No 4 3 undergraduate 3 3 Peaceful Analyze the situation and handle it with intellect No 4 5"},{"location":"KNN/main/#pre-processamento","title":"Pr\u00e9-processamento","text":""},{"location":"KNN/main/#remocao-de-colunas-irrelevantes","title":"Remo\u00e7\u00e3o de colunas irrelevantes","text":"<p>A coluna Timestamp foi removida por n\u00e3o agregar informa\u00e7\u00f5es para a previs\u00e3o.</p>"},{"location":"KNN/main/#variavel-alvo","title":"Vari\u00e1vel-alvo","text":"<p>A vari\u00e1vel alvo \u00e9 Stress. Por problemas na acuracia do modelo e ap\u00f3s alguns testes, decidi que ao inv\u00e9s de utilizar 5 grupos, um para cada tipo de stress, dividi em apenas 2, onde 1 o  nivel \u00e9 abaixo de 3 e 0, onde o n\u00edvel \u00e9 3 ou maior</p>"},{"location":"KNN/main/#tratamento-de-valores-ausentes","title":"Tratamento de valores ausentes","text":"<p>Foi identificado apenas um valor nulo em StudyEnv (ambiente de estudo), que foi preenchido com o valor mais frequente (Peaceful).</p>"},{"location":"KNN/main/#codificacao-de-variaveis-categoricas","title":"Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas","text":"<p>As colunas AcademicStage, StudyEnv, Strategy e BadHabits s\u00e3o categ\u00f3ricas e foram convertidas para valores num\u00e9ricos utilizando Label Encoding.</p>"},{"location":"KNN/main/#features-e-target","title":"Features e target","text":"<p>features (X): est\u00e1gio acad\u00eamico, press\u00e3o dos colegas, press\u00e3o da fam\u00edlia, ambiente de estudo, estrat\u00e9gia de enfrentamento, h\u00e1bitos nocivos, n\u00edvel de competi\u00e7\u00e3o acad\u00eamica.  </p> <p>target (y): \u00edndice de estresse acad\u00eamico.</p>"},{"location":"KNN/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>Os dados foram divididos de forma estratificada em 80% treino e 20% teste, garantindo que as propor\u00e7\u00f5es entre as classes de estresse fossem preservadas.</p>"},{"location":"KNN/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"KNNcode <p>Accuracy: 0.82 Feature Importances (Permutation):  Feature Importance Std AcademicComp 0.097024 0.040111 HomePressure 0.040476 0.032581 AcademicStage 0.036905 0.020585 BadHabits 0.016667 0.034173 PeerPressure 0.011905 0.025394 StudyEnv 0.002381 0.019956 Strategy -0.001786 0.016846 2025-12-05T14:06:25.031307 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nimport seaborn as sns\nimport pandas as pd\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom itertools import cycle\n\nplt.figure(figsize=(12, 10))\n\n# Preprocess the data\ndef preprocess(df: pd.DataFrame) -&gt; pd.DataFrame:\n    # remocao da coluna Timestamp\n    df = df.drop(columns=['Timestamp'])\n\n    # Tratamento de missing values\n    ## 'Study Environment' tem 1 valor ausente -&gt; preenchid com a moda (valor mais frequente)\n    df['StudyEnv'] = df['StudyEnv'].fillna(df['StudyEnv'].mode().iloc[0])\n\n    #conversao de variaveis categoricas\n    label_encoder = LabelEncoder()\n    df['AcademicStage'] = label_encoder.fit_transform(df['AcademicStage'])\n    df['StudyEnv'] = label_encoder.fit_transform(df['StudyEnv'])\n    df['Strategy'] = label_encoder.fit_transform(df['Strategy'])\n    df['BadHabits'] = label_encoder.fit_transform(df['BadHabits'])\n\n    # Selecao de features\n    features = [\n        'AcademicStage',                       \n        'PeerPressure',                       \n        'HomePressure',    \n        'StudyEnv',                            \n        'Strategy',                      \n        'BadHabits',\n        'AcademicComp' \n    ]\n\n    return df[features]\n\n\n# Carregar base\ndf = pd.read_csv('https://raw.githubusercontent.com/tigasparzin/Machine-Learning/refs/heads/main/data/StressExp.csv')\n\nd = preprocess(df.copy())\n\nX = d[['AcademicStage','PeerPressure',                       \n        'HomePressure',    \n        'StudyEnv',                            \n        'Strategy',                      \n        'BadHabits',\n        'AcademicComp']]\n# alvo bin\u00e1rio: baixo (&lt;3) e alto (&gt;=3)\ny = (df['Stress'] &gt;= 3).map({False: 1, True: 0})\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train KNN model\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n\nr = permutation_importance(\n    knn,                  \n    X_test,               \n    y_test,               \n    n_repeats=30,         \n    random_state=42,\n    scoring='accuracy'    \n)\n\n\nfeature_importance = pd.DataFrame({\n    'Feature': X.columns,\n    'Importance': r.importances_mean,\n    'Std': r.importances_std\n})\n\nreport_dict = classification_report(y_test, predictions, output_dict=True)\nreport_df = pd.DataFrame(report_dict).transpose()\n\ncm = confusion_matrix(y_test, predictions)\nlabels = knn.classes_\ncm_df = pd.DataFrame(cm, index=labels, columns=labels)\n\n# ordenar e mostrar (HTML igual ao seu exemplo)\nfeature_importance = feature_importance.sort_values(by='Importance', ascending=False)\nprint(\"&lt;br&gt;Feature Importances (Permutation):\")\nprint(feature_importance.to_html(index=False))\n\n# print(\"&lt;h3&gt;Relat\u00f3rio de Classifica\u00e7\u00e3o:&lt;/h3&gt;\")\n# print(report_df.to_html(classes=\"table table-bordered table-striped\", border=0))\n\n# Escalar features\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X)\n\n# Reduzir para 2 dimens\u00f5es (apenas para visualiza\u00e7\u00e3o)\npca = PCA(n_components=2)\nX_pca = pca.fit_transform(X_scaled)\n\n# Split train/test\nX_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.3, random_state=42)\n\n# Treinar KNN\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\n\n\n# Visualize decision boundary\nh = 0.02  # Step size in mesh\nx_min, x_max = X_pca[:, 0].min() - 1, X_pca[:, 0].max() + 1\ny_min, y_max = X_pca[:, 1].min() - 1, X_pca[:, 1].max() + 1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n\nZ = knn.predict(np.c_[xx.ravel(), yy.ravel()])\nZ = Z.reshape(xx.shape)\n\nplt.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu, alpha=0.3)\nsns.scatterplot(x=X_pca[:, 0], y=X_pca[:, 1], hue=y, style=y, palette=\"deep\", s=100)\nplt.xlabel(\"Feature 1\")\nplt.ylabel(\"Feature 2\")\nplt.title(\"KNN Decision Boundary (k=3)\")\n\n# Display the plot\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</code></pre>"},{"location":"KNN/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"Confusion Matrixcode <p>Accuracy: 0.82  2025-12-05T14:06:25.234373 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\n# carregar os dados\ndf = pd.read_csv('https://raw.githubusercontent.com/tigasparzin/Machine-Learning/refs/heads/main/data/StressExp.csv')\n\n# Preprocess the data\ndef preprocess(df: pd.DataFrame) -&gt; pd.DataFrame:\n    # remocao da coluna Timestamp\n    df = df.drop(columns=['Timestamp'])\n\n    # Tratamento de missing values\n    ## 'Study Environment' tem 1 valor ausente -&gt; preenchid com a moda (valor mais frequente)\n    df['StudyEnv'] = df['StudyEnv'].fillna(df['StudyEnv'].mode().iloc[0])\n\n    #conversao de variaveis categoricas\n    label_encoder = LabelEncoder()\n    df['AcademicStage'] = label_encoder.fit_transform(df['AcademicStage'])\n    df['StudyEnv'] = label_encoder.fit_transform(df['StudyEnv'])\n    df['Strategy'] = label_encoder.fit_transform(df['Strategy'])\n    df['BadHabits'] = label_encoder.fit_transform(df['BadHabits'])\n\n    # Selecao de features\n    features = [\n        'AcademicStage',                       \n        'PeerPressure',                       \n        'HomePressure',    \n        'StudyEnv',                            \n        'Strategy',                      \n        'BadHabits',\n        'AcademicComp' \n    ]\n\n    return df[features]\n\n\nd = preprocess(df.copy())\n\nX = d[['AcademicStage','PeerPressure',                       \n        'HomePressure',    \n        'StudyEnv',                            \n        'Strategy',                      \n        'BadHabits',\n        'AcademicComp']]\n# alvo bin\u00e1rio: baixo (&lt;3) e alto (&gt;=3)\ny = (df['Stress'] &gt;= 3).map({False: 1, True: 0})\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Train KNN model\nknn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\npredictions = knn.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, predictions):.2f}\")\n\n# gerar matriz de confus\u00e3o\nlabels = np.sort(np.unique(np.concatenate([y_test, predictions])))\ncm = confusion_matrix(y_test, predictions, labels=labels)\n\n# plotar matriz de confus\u00e3o\nfig, ax = plt.subplots(figsize=(8, 6))\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\ndisp.plot(ax=ax, cmap=plt.cm.Blues, values_format=\"d\", colorbar=False)\n\nax.set_title(\"Matriz de Confus\u00e3o - KNN\")\nax.set_xlabel(\"Previsto\")\nax.set_ylabel(\"Real\")\n\n# exportar para SVG\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True, bbox_inches=\"tight\")\nsvg_text = buffer.getvalue()\nprint(svg_text)\n\nplt.close(fig)\n</code></pre>"},{"location":"KNN/main/#sobre-binarizacao-no-alvo","title":"Sobre binariza\u00e7\u00e3o no alvo","text":"<p>Durante os primeiros modelos de teste, com os 5 niveis de estresse, estava tendo resultados com acuracias como 52% e ap\u00f3s mudan\u00e7as no modelo para tentar aumentar esse valor, chegando at\u00e9 no maximo 65%, ent\u00e3o percebi que o erro poderia estar, na quantidade, assim tive a ideia de classificar os niveis de estresse como altos (=&lt; 3) e baixos(&lt; 3), assim chegando em uma acuracia de 82%.</p>"},{"location":"KNN/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O uso do KNN nesta base evidenciou pontos importantes para o aprendizado:</p> <ul> <li> <p>O desbalanceamento das classes afeta a performance: n\u00edveis baixos de estresse (1 e 2) s\u00e3o pouco representados, o que dificulta acertos nessas classes.</p> </li> <li> <p>O modelo se mostrou sens\u00edvel \u00e0 escolha das vari\u00e1veis de entrada e ao valor de k. Testes com diferentes combina\u00e7\u00f5es podem alterar significativamente a acur\u00e1cia.  </p> </li> <li> <p>A normaliza\u00e7\u00e3o/standardiza\u00e7\u00e3o das vari\u00e1veis num\u00e9ricas \u00e9 fundamental para que todas as features tenham peso similar na dist\u00e2ncia euclidiana usada pelo KNN.  </p> </li> <li> <p>T\u00e9cnicas como binariza\u00e7\u00e3o do alvo (baixo vs. alto estresse) podem ser boas alternativas dependendo do objetivo da an\u00e1lise.  </p> </li> </ul> <p>Assim, o projeto refor\u00e7a a import\u00e2ncia do pr\u00e9-processamento cuidadoso, da aten\u00e7\u00e3o ao balanceamento de classes e da an\u00e1lise cr\u00edtica dos resultados para que o modelo seja \u00fatil de acordo com o problema real.</p>"},{"location":"SVM/main/","title":"SVM","text":""},{"location":"SVM/main/#analise-indice-de-estresse-academico-svm-com-kernels","title":"An\u00e1lise \u2013 \u00cdndice de Estresse Acad\u00eamico (SVM com kernels)","text":""},{"location":"SVM/main/#exploracao-dos-dados","title":"Explora\u00e7\u00e3o dos Dados","text":"<p>A base StressExp possui 280 registros e 9 colunas (<code>Timestamp</code>, <code>AcademicStage</code>, <code>PeerPressure</code>, <code>HomePressure</code>, <code>StudyEnv</code>, <code>Strategy</code>, <code>BadHabits</code>, <code>AcademicComp</code>, <code>Stress</code>).</p> <p>Para o experimento com SVM, o c\u00f3digo utiliza apenas duas vari\u00e1veis num\u00e9ricas como features:</p> <ul> <li>PeerPressure (press\u00e3o dos colegas \u2013 escala 1\u20135)  </li> <li>HomePressure (press\u00e3o acad\u00eamica da fam\u00edlia \u2013 escala 1\u20135)</li> </ul> <p>A vari\u00e1vel original Stress \u00e9 um \u00edndice de estresse de 1 a 5, aproximadamente balanceado nos 5 n\u00edveis, com m\u00e9dia pr\u00f3xima de 3, como identificado anteriormente.</p> <p>Esse recorte reduz o problema a um plano 2D, permitindo a visualiza\u00e7\u00e3o das fronteiras de decis\u00e3o, mas ignorando vari\u00e1veis relevantes como <code>AcademicComp</code>, <code>StudyEnv</code>, <code>BadHabits</code>, etc.</p>"},{"location":"SVM/main/#pre-processamento","title":"Pr\u00e9-processamento","text":""},{"location":"SVM/main/#colunas-utilizadas","title":"Colunas utilizadas","text":"<p>O modelo SVM usa apenas:</p> <ul> <li><code>PeerPressure</code></li> <li><code>HomePressure</code></li> </ul>"},{"location":"SVM/main/#variavel-alvo-binarizacao","title":"Vari\u00e1vel-alvo (binariza\u00e7\u00e3o)","text":"<p>O target \u00e9 reduzido de cinco n\u00edveis para duas classes:</p> <ul> <li><code>Stress &gt;= 4</code> \u2192 alto estresse </li> <li><code>Stress &lt;= 3</code> \u2192 baixo estresse </li> </ul> <p>Na implementa\u00e7\u00e3o:</p> <pre><code>0 = alto estresse  \n1 = baixo estresse\n</code></pre>"},{"location":"SVM/main/#missing-values","title":"Missing values","text":"<p>Nenhum dos dois atributos utilizados apresenta valores nulos, portanto nenhuma imputa\u00e7\u00e3o foi necess\u00e1ria.</p>"},{"location":"SVM/main/#normalizacao","title":"Normaliza\u00e7\u00e3o","text":"<p>N\u00e3o h\u00e1 normaliza\u00e7\u00e3o no c\u00f3digo original, o que pode prejudicar kernels como RBF, sigmoid e poly.</p>"},{"location":"SVM/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>O c\u00f3digo N\u00c3O separa treino e teste: o modelo \u00e9 treinado e visualizado na pr\u00f3pria base completa.</p> <p>Isso impede a avalia\u00e7\u00e3o real de desempenho, tornando o experimento puramente visual/explorat\u00f3rio.</p>"},{"location":"SVM/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"<p>O script treina quatro SVMs com <code>C = 1</code>, variando o kernel:</p> <ul> <li>Linear</li> <li>Sigmoid</li> <li>Poly</li> <li>RBF</li> </ul> avaliacao do modelocode 2025-12-05T14:06:25.654610 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <pre><code>import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.inspection import DecisionBoundaryDisplay\nfrom sklearn.svm import SVC\nfrom io import StringIO\n\n# Carrega a base\ndf = pd.read_csv('https://raw.githubusercontent.com/tigasparzin/Machine-Learning/refs/heads/main/data/StressExp.csv')\n\n# Binariza\u00e7\u00e3o\ny = (df['Stress'] &gt;= 4).map({False: 1, True: 0})\n\n# Usa duas vari\u00e1veis num\u00e9ricas como features\nX = df[[\"PeerPressure\", \"HomePressure\"]].values\n\nfig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(10, 6))\n\nkernels = {\n    'linear': ax1,\n    'sigmoid': ax2,\n    'poly': ax3,\n    'rbf': ax4\n}\n\nfor k, ax in kernels.items():\n    svm = SVC(kernel=k, C=1)\n    svm.fit(X, y)\n\n    DecisionBoundaryDisplay.from_estimator(\n        svm,\n        X,\n        response_method=\"predict\",\n        alpha=0.8,\n        cmap=\"Pastel1\",\n        ax=ax\n    )\n\n    ax.scatter(\n        X[:, 0], X[:, 1],\n        c=y,\n        s=20, edgecolors=\"black\"\n    )\n\n    ax.set_title(k)\n    ax.set_xticks([])\n    ax.set_yticks([])\n\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\nplt.close()\n</code></pre> <p>Ap\u00f3s treinar, o c\u00f3digo plota as regi\u00f5es de decis\u00e3o em 2D, permitindo compara\u00e7\u00e3o visual.</p>"},{"location":"SVM/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>Como n\u00e3o h\u00e1 m\u00e9tricas, apenas observa\u00e7\u00f5es qualitativas podem ser feitas:</p> <ul> <li>Usar duas features limita severamente o poder do modelo.  </li> <li>Kernels n\u00e3o lineares provavelmente mostram melhor separa\u00e7\u00e3o visual.  </li> </ul>"},{"location":"SVM/main/#conclusao","title":"Conclus\u00e3o","text":"<ul> <li>O SVM bin\u00e1rio \u00e9 mais coerente com a estrutura do algoritmo.  </li> <li>O experimento atual \u00e9 \u00fatil para visualiza\u00e7\u00e3o did\u00e1tica das fronteiras de decis\u00e3o.  </li> <li>Para uma an\u00e1lise robusta, seria melhor utilizar normaliza\u00e7\u00e3o e mais atributos.</li> </ul>"},{"location":"arvore-decisao/main/","title":"Arvore de decisao","text":""},{"location":"arvore-decisao/main/#exploracao-dos-dados","title":"Explora\u00e7\u00e3o dos Dados","text":"<p>A base possui 140 registros e 9 colunas.</p> <p>Est\u00e1gio acad\u00eamico: Referente a qual estagio academico o respondente est\u00e1. Sendo 71% estudantes de gradua\u00e7\u00e3o, 21% no ensino m\u00e9dio e 8% de p\u00f3s gradua\u00e7\u00e3o.</p> <p>Press\u00e3o dos colegas: O quanto o aluno se sente pressionado pelos colegas numa escala de 1 a 5, com m\u00e9dia das respostas de 3,07.</p> <p>Press\u00e3o acad\u00eamica da fam\u00edlia: O quanto o aluno se sente pressionado pela familia numa escala de 1 a 5, com m\u00e9dia das respostas de 3,17.</p> <p>Ambiente de estudo: Como o aluno classifica o ambiente onde estuda entre as categorias: Peaceful (49% das respostas), Noisy(24% das respostas) e Disrupted(27% das respostas).</p> <p>Estrat\u00e9gia de enfrentamento: Como o aluno enfrenta o estresse, entre as op\u00e7\u00f5es: Analisar a situacao com inteligencia (62%), Colapso emocional (23%), apoio de amigo/familia (15%).</p> <p>Maus habitos: Diz se o respondente tem maus habitos, como fumar ou beber, entre as op\u00e7\u00f5es: \"N\u00e3o\" (88%), \"Sim\" (7%) e 5% preferiram n\u00e3o responder.</p> <p>Competi\u00e7\u00e3o acad\u00eamica: Classificar a competicao academica na sua vida, em uma escala escala de 1 a 5, tendo m\u00e9dia das respostas de 3,49.</p> <p>\u00cdndice de estresse: Classificar o nivel de estresse academico, em uma escala de 1 a 5, tendo m\u00e9dia de 3,72.</p> AcademicStage PeerPressure HomePressure StudyEnv Strategy BadHabits AcademicComp Stress undergraduate 4 5 Noisy Analyze the situation and handle it with intellect No 3 5 undergraduate 3 4 Peaceful Analyze the situation and handle it with intellect No 3 3 undergraduate 1 1 Peaceful Social support (friends, family) No 2 4 undergraduate 3 2 Peaceful Analyze the situation and handle it with intellect No 4 3 undergraduate 3 3 Peaceful Analyze the situation and handle it with intellect No 4 5"},{"location":"arvore-decisao/main/#pre-processamento","title":"Pr\u00e9-processamento","text":""},{"location":"arvore-decisao/main/#remocao-de-colunas-irrelevantes","title":"Remo\u00e7\u00e3o de colunas irrelevantes","text":"<p>A coluna Timestamp foi removida por n\u00e3o agregar informa\u00e7\u00f5es para a previs\u00e3o.</p>"},{"location":"arvore-decisao/main/#variavel-alvo","title":"Vari\u00e1vel-alvo","text":"<p>A vari\u00e1vel alvo definida foi \"Rate your academic stress index\".</p>"},{"location":"arvore-decisao/main/#tratamento-de-missing-value","title":"Tratamento de missing value","text":"<p>A base apresenta apenas um valor nulo em Study Environment, que ser\u00e1 preenchido com \"Peaceful\", valor mais frequente.</p>"},{"location":"arvore-decisao/main/#codificacao-de-variaveis-categoricas","title":"Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas","text":"<p>As colunas \"Your Academic Stage\", \"Study Environment\", \"What coping strategy you use as a student?\" e \"Do you have any bad habits?\", s\u00e3o categ\u00f3ricas.</p> <p>Foram convertidas em valores num\u00e9ricos utilizando Label Encoding, para que a \u00e1rvore de decis\u00e3o consiga interpret\u00e1-las.</p>"},{"location":"arvore-decisao/main/#features-e-target","title":"Features e target","text":"<p>feature (X): est\u00e1gio acad\u00eamico, press\u00e3o dos colegas, press\u00e3o da fam\u00edlia, ambiente de estudo, estrat\u00e9gia de enfrentamento, h\u00e1bitos nocivos, n\u00edvel de competi\u00e7\u00e3o acad\u00eamica.</p> <p>target (y): \u00edndice de estresse acad\u00eamico (1 a 5).</p>"},{"location":"arvore-decisao/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>80% dos registros da base foram separados para treino e 20% separados para testes de acuracia</p>"},{"location":"arvore-decisao/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"decision treecode <p>Accuracy: 0.75  2025-12-05T14:06:26.072535 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ </p> <pre><code>import matplotlib.pyplot as plt\nimport pandas as pd\n\nfrom io import StringIO\nfrom sklearn import tree\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\n# Preprocess the data\ndef preprocess(df: pd.DataFrame) -&gt; pd.DataFrame:\n    # remocao da coluna Timestamp\n    df = df.drop(columns=['Timestamp'])\n\n    # Tratamento de missing values\n    ## 'Study Environment' tem 1 valor ausente -&gt; preenchid com a moda (valor mais frequente)\n    df['StudyEnv'].fillna(df['StudyEnv'].mode()[0], inplace=True)\n\n    #conversao de variaveis categoricas\n    label_encoder = LabelEncoder()\n    df['AcademicStage'] = label_encoder.fit_transform(df['AcademicStage'])\n    df['StudyEnv'] = label_encoder.fit_transform(df['StudyEnv'])\n    df['Strategy'] = label_encoder.fit_transform(df['Strategy'])\n    df['BadHabits'] = label_encoder.fit_transform(df['BadHabits'])\n\n    # Selecao de features\n    features = [\n        'AcademicStage',                       \n        'PeerPressure',                       \n        'HomePressure',    \n        'StudyEnv',                            \n        'Strategy',                      \n        'BadHabits',\n        'AcademicComp' \n    ]\n\n    return df[features]\n\n\nplt.figure(figsize=(12, 10))\n\n# Carregar base\ndf = pd.read_csv('https://raw.githubusercontent.com/tigasparzin/Machine-Learning/refs/heads/main/data/StressExp.csv')\n\n# Vari\u00e1veis de entrada e alvo\nX = preprocess(df)\ny = df['Stress']\n\n# Dividir os dados em conjuntos de treinamento e teste\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42\n)\n\n# Criar e treinar o modelo de \u00e1rvore de decis\u00e3o\nclassifier = tree.DecisionTreeClassifier()\nclassifier.fit(X_train, y_train)\n\n# Avaliar o modelo\naccuracy = classifier.score(X_test, y_test)\nprint(f\"Accuracy: {accuracy:.2f}\")\ntree.plot_tree(classifier)\n\n# Para imprimir na p\u00e1gina HTML\nbuffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</code></pre>"},{"location":"arvore-decisao/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>Rodando o modelo e prestando mais aten\u00e7\u00e3o na base, percebi que haviam apenas 15 registros onde meu target era menor do que 3, o que acabava deixando meu modelo com underfittig, tendo acuracia de apenas 36%. Para solucionar este problema, criei dados sinteticos. Balanceando a quantidade de dados em cada nivel de stress</p>"},{"location":"arvore-decisao/main/#populacao-da-base","title":"Popula\u00e7\u00e3o da base.","text":"<p>Fui adicionando registros aos poucos, para tentar chegar no melhor resultado com a menor quantidade de dados sint\u00e9ticos possivel. Para chegar no modelo atual, distribu\u00ed 100 novos registros da seguinte maneira:</p> <pre><code>Stress = 1 \u2192 +30 registros\nStress = 2 \u2192 +27 registros\nStress = 3 \u2192 +20 registros\nStress = 4 \u2192 +0 registros\nStress = 5 \u2192 +23 registro\n</code></pre> <p>Ap\u00f3s essas altera\u00e7\u00f5es, a acuracia subiu para 73%.</p>"},{"location":"arvore-decisao/main/#conclusao","title":"Conclus\u00e3o","text":"<p>Ao realizar esse projeto, entendi a necessidade de fazer um pr\u00e9-processamento dos dados, visto que nem sempre a base vir\u00e1 de acordo com o que o projeto exige e tamb\u00e9m o impacto de que a frequencia dos dados registrados impacta diretamente na acuracia. Diante de um problema na precis\u00e3o do meu modelo, tive que buscar solu\u00e7\u00f5es alternativas, como a gera\u00e7\u00e3o de daos sint\u00e9ticos. Acho v\u00e1lido adicionar tamb\u00e9m que avaliar se a acuracia est\u00e1 boa ou n\u00e3o, dependeria da proposta do projeto, visto que casos diferentes tem consequencias diferentes.</p>"},{"location":"pageRank/main/","title":"Page Rank","text":""},{"location":"pageRank/main/#analise-de-pagerank-na-rede-de-confianca-soc-epinions1","title":"An\u00e1lise de PageRank na rede de confian\u00e7a soc-Epinions1","text":""},{"location":"pageRank/main/#1-objetivo","title":"1. Objetivo","text":"<p>O objetivo deste trabalho \u00e9 implementar do zero o algoritmo PageRank em um grafo dirigido real, comparar os resultados com a implementa\u00e7\u00e3o pronta do NetworkX e analisar os n\u00f3s mais importantes da rede em fun\u00e7\u00e3o de diferentes valores do fator de amortecimento \\(d\\).  </p> <p>O dataset escolhido foi soc-Epinions1, que representa uma rede de confian\u00e7a entre usu\u00e1rios do site de reviews Epinions. Em termos conceituais:</p> <ul> <li>N\u00f3 = usu\u00e1rio da plataforma;  </li> <li>Aresta dirigida A \u2192 B = o usu\u00e1rio A confia no usu\u00e1rio B.</li> </ul> <p>A aplica\u00e7\u00e3o do PageRank, nesse contexto, permite identificar usu\u00e1rios que s\u00e3o n\u00e3o apenas muito confiados diretamente, mas tamb\u00e9m confiados por outros usu\u00e1rios igualmente confi\u00e1veis \u2013 ou seja, potenciais influenciadores na comunidade.</p>"},{"location":"pageRank/main/#2-dataset-e-modelagem-do-grafo","title":"2. Dataset e modelagem do grafo","text":"<p>O arquivo de arestas <code>soc-Epinions1.txt</code> foi carregado diretamente como um grafo dirigido:</p> <ul> <li>Biblioteca utilizada: <code>networkx</code> (<code>nx.DiGraph()</code>);  </li> <li>Coment\u00e1rios iniciados por <code>#</code> foram ignorados;  </li> <li>IDs de n\u00f3s foram lidos como inteiros.</li> </ul> <p>Ap\u00f3s o carregamento:</p> <ul> <li>N\u00famero de n\u00f3s: 75.879 </li> <li>N\u00famero de arestas dirigidas: 508.837</li> </ul> <p>Modelagem adotada:</p> <ul> <li>Uma aresta A \u2192 B significa que A confia em B;  </li> <li>O grafo \u00e9 mantido como dirigido (n\u00e3o foi simetrizado).</li> </ul> <p>Essa modelagem \u00e9 coerente com a interpreta\u00e7\u00e3o original da rede: a confian\u00e7a \u00e9 assim\u00e9trica (eu posso confiar em voc\u00ea sem que voc\u00ea necessariamente confie em mim).</p>"},{"location":"pageRank/main/#3-implementacao-do-pagerank-do-zero","title":"3. Implementa\u00e7\u00e3o do PageRank do zero","text":""},{"location":"pageRank/main/#31-estrutura-de-dados","title":"3.1. Estrutura de dados","text":"<p>Para evitar uma matriz de transi\u00e7\u00e3o \\(N \\times N\\) (invi\u00e1vel para ~76k n\u00f3s), foi usada uma representa\u00e7\u00e3o baseada em listas de adjac\u00eancia:</p> <ul> <li><code>nodes</code>: lista de n\u00f3s (IDs inteiros)  </li> <li><code>node_to_idx</code>: mapeia ID do n\u00f3 \u2192 \u00edndice [0..N-1]  </li> <li><code>out_neighbors[i]</code>: lista de \u00edndices dos n\u00f3s alcan\u00e7ados por arestas que saem do n\u00f3 de \u00edndice <code>i</code>;  </li> <li><code>out_degree[i]</code>: grau de sa\u00edda de cada n\u00f3.</li> </ul> <p>Esses vetores permitem que o algoritmo rode em \\(O(N + E)\\) por itera\u00e7\u00e3o, sem explodir mem\u00f3ria.</p>"},{"location":"pageRank/main/#32-formula-iterativa","title":"3.2. F\u00f3rmula iterativa","text":"<p>A implementa\u00e7\u00e3o segue a f\u00f3rmula cl\u00e1ssica:</p> \\[ PR(p_i) = \\frac{1-d}{N}  + d \\sum_{p_j \\in M(p_i)} \\frac{PR(p_j)}{L(p_j)} \\] <p>Onde:</p> <ul> <li>\\(d\\) \u00e9 o fator de amortecimento (teletransporte);  </li> <li>\\(N\\) \u00e9 o n\u00famero de n\u00f3s;  </li> <li>\\(M(p_i)\\) \u00e9 o conjunto de n\u00f3s que apontam para \\(p_i\\);  </li> <li>\\(L(p_j)\\) \u00e9 o n\u00famero de liga\u00e7\u00f5es de sa\u00edda de \\(p_j\\).</li> </ul> <p>Tratamento de n\u00f3s \u201cdangling\u201d (sem sa\u00eddas) N\u00f3s com grau de sa\u00edda zero acumulam PageRank que n\u00e3o \u00e9 redistribu\u00eddo via arestas. Para corrigir isso, foi usada a estrat\u00e9gia padr\u00e3o:</p> <ul> <li>Soma-se a \u201cmassa\u201d de PageRank de todos os n\u00f3s sem sa\u00edda (<code>dangling_sum</code>) e redistribui-se igualmente entre todos os n\u00f3s, multiplicada por \\(d\\).</li> </ul>"},{"location":"pageRank/main/#33-criterio-de-convergencia","title":"3.3. Crit\u00e9rio de converg\u00eancia","text":"<ul> <li>Inicializa\u00e7\u00e3o: \\(PR_i^{(0)} = 1/N\\) para todos os n\u00f3s;  </li> <li>A cada itera\u00e7\u00e3o, \u00e9 calculado um novo vetor <code>pr_new</code>;  </li> <li>M\u00e9trica de converg\u00eancia:   [   \\max_i |PR_i^{(t+1)} - PR_i^{(t)}|   ]</li> <li>Se essa diferen\u00e7a m\u00e1xima ficar abaixo de <code>tol = 1e-6</code>, o algoritmo para;  </li> <li>Limite de itera\u00e7\u00f5es: <code>max_iter = 100</code>.</li> </ul>"},{"location":"pageRank/main/#4-validacao-contra-networkxpagerank","title":"4. Valida\u00e7\u00e3o contra <code>networkx.pagerank</code>","text":"<p>Para \\(d = 0{,}85\\) (valor padr\u00e3o cl\u00e1ssico), os resultados da implementa\u00e7\u00e3o pr\u00f3pria foram comparados com <code>nx.pagerank(G, alpha=0.85)</code>:</p> <ul> <li>Diferen\u00e7a L1 total (soma dos m\u00f3dulos das diferen\u00e7as):   [   \\approx 8{,}88 \\times 10^{-4}   ]</li> <li>Diferen\u00e7a m\u00e1xima entre qualquer n\u00f3:   [   \\approx 1{,}93 \\times 10^{-5}   ]</li> </ul> <p>O algoritmo pr\u00f3prio convergiu em 31 itera\u00e7\u00f5es para \\(d = 0{,}85\\).</p> <p>Esses valores de diferen\u00e7a s\u00e3o muito pequenos e est\u00e3o dentro do esperado para m\u00e9todos iterativos com toler\u00e2ncias ligeiramente diferentes, o que indica que a implementa\u00e7\u00e3o est\u00e1 correta e consistente com a refer\u00eancia do NetworkX.</p>"},{"location":"pageRank/main/#5-resultados-nos-mais-importantes","title":"5. Resultados: n\u00f3s mais importantes","text":"<p>Foram avaliados tr\u00eas valores de fator de amortecimento:</p> <ul> <li>\\(d = 0{,}50\\) </li> <li>\\(d = 0{,}85\\) </li> <li>\\(d = 0{,}99\\)</li> </ul>"},{"location":"pageRank/main/#51-convergencia","title":"5.1. Converg\u00eancia","text":"<ul> <li>\\(d = 0{,}50\\) </li> <li>Converg\u00eancia em 7 itera\u00e7\u00f5es.  </li> <li>\\(d = 0{,}85\\) </li> <li>Converg\u00eancia em 31 itera\u00e7\u00f5es.  </li> <li>\\(d = 0{,}99\\) </li> <li>N\u00e3o convergiu dentro de 100 itera\u00e7\u00f5es para <code>tol = 1e-6</code> (ou seja, precisaria de mais itera\u00e7\u00f5es ou toler\u00e2ncia mais frouxa).</li> </ul> <p>Isso j\u00e1 mostra um comportamento importante: quanto maior o \\(d\\) (menor peso do teletransporte), mais lenta a converg\u00eancia.</p>"},{"location":"pageRank/main/#52-top-10-nos-para-d-085","title":"5.2. Top 10 n\u00f3s para \\(d = 0{,}85\\)","text":"<p>A tabela abaixo resume os 10 n\u00f3s com maior PageRank para \\(d = 0{,}85\\), com respectivos graus de entrada/sa\u00edda:</p> Posi\u00e7\u00e3o N\u00f3 PageRank Grau de entrada Grau de sa\u00edda 1 18 4.535e-03 3035 44 2 737 3.151e-03 1317 372 3 118 2.122e-03 1004 123 4 1719 2.078e-03 1140 46 5 136 1.987e-03 1180 111 6 790 1.969e-03 1284 102 7 143 1.957e-03 1521 171 8 40 1.825e-03 817 238 9 1619 1.536e-03 784 123 10 725 1.496e-03 694 274 <p>Observa\u00e7\u00f5es:</p> <ul> <li>Todos esses n\u00f3s apresentam graus de entrada muito altos (centenas a milhares de usu\u00e1rios que confiam neles);  </li> <li>Alguns tamb\u00e9m t\u00eam graus de sa\u00edda elevados (como os n\u00f3s 737, 40 e 725), o que sugere que eles tamb\u00e9m confiam em muitos outros, atuando como \u201chubs\u201d de confian\u00e7a.</li> </ul>"},{"location":"pageRank/main/#53-top-10-nos-para-outros-valores-de-d","title":"5.3. Top 10 n\u00f3s para outros valores de \\(d\\)","text":"<p>Para \\(d = 0{,}50\\), o top 10 \u00e9 muito parecido com o de \\(d = 0{,}85\\):</p> <ul> <li>N\u00f3 18 continua em 1\u00ba lugar;  </li> <li>N\u00f3s como 737, 790, 1719, 143, 136 e 118 aparecem nos primeiros lugares;  </li> <li>As diferen\u00e7as s\u00e3o pequenas na ordena\u00e7\u00e3o e na concentra\u00e7\u00e3o dos scores.</li> </ul> <p>Para \\(d = 0{,}99\\):</p> <ul> <li>O n\u00f3 18 continua l\u00edder (PR ainda maior);  </li> <li>737 permanece no topo;  </li> <li>Surgem n\u00f3s como 22933 e 8648 com PageRank bem alto apesar de terem graus de entrada modestos (23 e 102) e grau de sa\u00edda 1.  </li> <li>Isso sugere que eles podem estar recebendo links de n\u00f3s muito influentes ou fazendo parte de \u201ccaminhos\u201d de confian\u00e7a que prendem a massa de PageRank quando o teletransporte \u00e9 raro.</li> </ul>"},{"location":"pageRank/main/#6-interpretacao-no-contexto-da-rede-epinions","title":"6. Interpreta\u00e7\u00e3o no contexto da rede Epinions","text":"<p>Mesmo sem metadados (nomes reais dos usu\u00e1rios, temas de reviews, etc.), \u00e9 poss\u00edvel interpretar qualitativamente:</p> <ol> <li>N\u00f3s com alt\u00edssimo grau de entrada e PageRank alto </li> <li>Ex.: n\u00f3s 18, 143, 790, 118, 136, 1719;  </li> <li>S\u00e3o usu\u00e1rios que recebem confian\u00e7a de muitos outros, incluindo possivelmente outros usu\u00e1rios influentes;  </li> <li> <p>Em um site de reviews, podem ser:</p> <ul> <li>\u201cTop reviewers\u201d;  </li> <li>Usu\u00e1rios antigos com hist\u00f3rico confi\u00e1vel;  </li> <li>Pessoas centrais em comunidades tem\u00e1ticas espec\u00edficas.</li> </ul> </li> <li> <p>Rela\u00e7\u00e3o entre grau e PageRank </p> </li> <li>PageRank n\u00e3o \u00e9 apenas \u201ccontar links\u201d:  <ul> <li>N\u00f3s com grau de entrada alto, mas conectados a usu\u00e1rios pouco influentes, tendem a ter PageRank menor do que n\u00f3s que recebem poucas, mas \u201cqualificadas\u201d conex\u00f5es;  </li> </ul> </li> <li> <p>A presen\u00e7a de n\u00f3s como 22933 e 8648 no top 10 com \\(d = 0{,}99\\) mostra isso: mesmo com poucos links de entrada, se esses links v\u00eam de n\u00f3s com PageRank alto, eles sobem muito no ranking.</p> </li> <li> <p>Papel do grau de sa\u00edda </p> </li> <li>Um n\u00f3 que \u201cespalha\u201d sua confian\u00e7a em muitos outros (grau de sa\u00edda alto) dilui seu impacto individual em cada destino;  </li> <li>J\u00e1 um n\u00f3 com grau de sa\u00edda 1 (como 22933 e 8648) concentra o PageRank recebido em um \u00fanico destino, o que pode formar pequenos \u201cciclos\u201d ou componentes que ret\u00eam massa de PageRank quando \\(d\\) \u00e9 elevado.</li> </ol>"},{"location":"pageRank/main/#7-impacto-da-variacao-do-fator-de-amortecimento-d","title":"7. Impacto da varia\u00e7\u00e3o do fator de amortecimento \\(d\\)","text":""},{"location":"pageRank/main/#71-d-050-teletransporte-forte","title":"7.1. \\(d = 0{,}50\\): teletransporte forte","text":"<ul> <li>O teletransporte tem um peso maior (50%);  </li> <li>O grafo importa, mas a aleatoriedade ajuda a \u201cdemocratizar\u201d o ranking;  </li> <li>O top 10 ainda \u00e9 dominado pelos grandes hubs de confian\u00e7a (18, 737, etc.), mas as diferen\u00e7as relativas s\u00e3o menores e a distribui\u00e7\u00e3o de PageRank tende a ser mais uniforme.</li> </ul>"},{"location":"pageRank/main/#72-d-085-valor-padrao-da-literatura","title":"7.2. \\(d = 0{,}85\\): valor \u201cpadr\u00e3o\u201d da literatura","text":"<ul> <li>Equil\u00edbrio entre estrutura de links e teletransporte;  </li> <li>Ranking est\u00e1vel, com boa separa\u00e7\u00e3o entre usu\u00e1rios muito influentes e o restante;  </li> <li>Converg\u00eancia moderadamente r\u00e1pida (31 itera\u00e7\u00f5es).</li> </ul>"},{"location":"pageRank/main/#73-d-099-quase-sem-teletransporte","title":"7.3. \\(d = 0{,}99\\): quase sem teletransporte","text":"<ul> <li>A import\u00e2ncia da estrutura de links fica extrema;  </li> <li>A converg\u00eancia fica lenta (n\u00e3o convergiu em 100 itera\u00e7\u00f5es com <code>tol=1e-6</code>);  </li> <li>Aparecem comportamentos \u201cestranhos\u201d:</li> <li>N\u00f3s com poucos links, mas conectados a clusters altamente conectados, sobem muito no ranking;  </li> <li>A massa de PageRank tende a se concentrar em componentes fortemente conexas que funcionam como \u201cburacos negros\u201d de confian\u00e7a.</li> </ul> <p>Em termos pr\u00e1ticos, isso mostra por que valores muito altos de \\(d\\) podem ser perigosos: o ranking fica mais sens\u00edvel a detalhes da estrutura da rede e a pequenas irregularidades.</p>"},{"location":"pageRank/main/#8-limitacoes-e-possiveis-extensoes","title":"8. Limita\u00e7\u00f5es e poss\u00edveis extens\u00f5es","text":"<p>Limita\u00e7\u00f5es:</p> <ul> <li>A an\u00e1lise \u00e9 feita apenas sobre IDs num\u00e9ricos; sem atributos dos usu\u00e1rios, n\u00e3o \u00e9 poss\u00edvel rotular os n\u00f3s (\u201cespecialistas em X\u201d, \u201cmoderadores\u201d, etc.);  </li> <li>N\u00e3o foram calculadas outras medidas de centralidade (grau, betweenness, closeness) para compara\u00e7\u00e3o quantitativa com o PageRank.</li> </ul> <p>Poss\u00edveis extens\u00f5es:</p> <ul> <li>Comparar PageRank com centralidade de grau para mostrar casos em que a recursividade do PageRank \u201ccorrige\u201d o ranking;  </li> <li>Analisar um subgrafo induzido pelos top 100 n\u00f3s (densidade, modularidade);  </li> <li>Estudar cen\u00e1rios com limiares diferentes de toler\u00e2ncia e outro crit\u00e9rio de parada (por exemplo, diferen\u00e7a no valor total de PageRank ou varia\u00e7\u00e3o da ordena\u00e7\u00e3o do top-k).</li> </ul>"},{"location":"pageRank/main/#9-conclusao","title":"9. Conclus\u00e3o","text":"<p>Neste trabalho:</p> <ol> <li>Foi implementado o algoritmo PageRank do zero, com tratamento de n\u00f3s sem sa\u00edda, crit\u00e9rio de converg\u00eancia por diferen\u00e7a m\u00e1xima e estrutura de dados eficiente baseada em listas de adjac\u00eancia.</li> <li>A implementa\u00e7\u00e3o foi validada contra <code>networkx.pagerank</code> para \\(d = 0{,}85\\), apresentando diferen\u00e7as num\u00e9ricas pequenas (diferen\u00e7a m\u00e1xima da ordem de \\(10^{-5}\\)), o que indica corre\u00e7\u00e3o do m\u00e9todo.</li> <li>Foram calculados os valores de PageRank da rede soc-Epinions1 para diferentes fatores de amortecimento (\\(d = 0{,}50\\), \\(0{,}85\\) e \\(0{,}99\\)), analisando converg\u00eancia e o comportamento do ranking.</li> <li>Identificou-se um conjunto est\u00e1vel de n\u00f3s altamente influentes (como o n\u00f3 18 e outros hubs de alta entrada) e observou-se como o aumento de \\(d\\) tende a concentrar o PageRank em componentes espec\u00edficas da rede, favorecendo alguns n\u00f3s adicionais quando a aleatoriedade \u00e9 reduzida.</li> </ol> <p>Do ponto de vista de aprendizado de m\u00e1quina em grafos e an\u00e1lise de redes, o exerc\u00edcio mostra claramente que:</p>"},{"location":"random-forest/main/","title":"Random Forest","text":""},{"location":"random-forest/main/#analise-indice-de-estresse-academico-random-forest","title":"An\u00e1lise \u2013 \u00cdndice de Estresse Acad\u00eamico (Random Forest)","text":""},{"location":"random-forest/main/#exploracao-dos-dados","title":"Explora\u00e7\u00e3o dos Dados","text":"<p>A base possui 280 registros e 9 colunas (<code>Timestamp</code>, <code>AcademicStage</code>, <code>PeerPressure</code>, <code>HomePressure</code>, <code>StudyEnv</code>, <code>Strategy</code>, <code>BadHabits</code>, <code>AcademicComp</code>, <code>Stress</code>).</p> <p>Distribui\u00e7\u00f5es e estat\u00edsticas principais:</p> <ul> <li>Est\u00e1gio acad\u00eamico (<code>AcademicStage</code>): undergraduate 63.57%, high school 22.14%, post-graduate 14.29%.</li> <li>Press\u00e3o dos colegas (<code>PeerPressure</code>): m\u00e9dia 3.01 (escala 1\u20135).</li> <li>Press\u00e3o acad\u00eamica da fam\u00edlia (<code>HomePressure</code>): m\u00e9dia 3.09 (1\u20135).</li> <li>Ambiente de estudo (<code>StudyEnv</code>): Peaceful 47.14%, Noisy 26.43%, disrupted 26.07%, e 0.36% ausente (1 valor nulo).</li> <li>Estrat\u00e9gia de enfrentamento (<code>Strategy</code>): Analyze the situation\u2026 54.29%, Emotional breakdown 26.79%, Social support 18.93%.</li> <li>Maus h\u00e1bitos (<code>BadHabits</code>): No 65.71%, Yes 18.93%, prefer not to say 15.36%.</li> <li>Competi\u00e7\u00e3o acad\u00eamica (<code>AcademicComp</code>): m\u00e9dia 3.27 (1\u20135).</li> <li>\u00cdndice de estresse (target) (<code>Stress</code>): balanceado \u2014 20.0% (1), 20.0% (2), 20.0% (3), 20.0% (4), 20.0% (5); m\u00e9dia 3.0.</li> </ul> AcademicStage PeerPressure HomePressure StudyEnv Strategy BadHabits AcademicComp Stress undergraduate 4 5 Noisy Analyze the situation and handle it with intellect No 3 5 undergraduate 3 4 Peaceful Analyze the situation and handle it with intellect No 3 3 undergraduate 1 1 Peaceful Social support (friends, family) No 2 4 undergraduate 3 2 Peaceful Analyze the situation and handle it with intellect No 4 3 undergraduate 3 3 Peaceful Analyze the situation and handle it with intellect No 4 5"},{"location":"random-forest/main/#pre-processamento","title":"Pr\u00e9-processamento","text":""},{"location":"random-forest/main/#remocao-de-colunas-irrelevantes","title":"Remo\u00e7\u00e3o de colunas irrelevantes","text":"<p>A coluna <code>Timestamp</code> foi removida por n\u00e3o agregar informa\u00e7\u00e3o para a previs\u00e3o.</p>"},{"location":"random-forest/main/#variavel-alvo","title":"Vari\u00e1vel-alvo","text":"<p>A vari\u00e1vel alvo definida foi <code>Stress</code> (\u00edndice de estresse acad\u00eamico: 1 a 5).</p>"},{"location":"random-forest/main/#tratamento-de-missing-value","title":"Tratamento de missing value","text":"<p>A base apresenta 1 valor nulo em <code>StudyEnv</code>. Preencher com Peaceful (moda) calculada somente nos dados de treino .</p>"},{"location":"random-forest/main/#codificacao-de-variaveis-categoricas","title":"Codifica\u00e7\u00e3o de vari\u00e1veis categ\u00f3ricas","text":"<p>As colunas <code>AcademicStage</code>, <code>StudyEnv</code>, <code>Strategy</code> e <code>BadHabits</code> s\u00e3o categ\u00f3ricas. O pipeline atual usa Label Encoding \u2014 v\u00e1lido para modelos de \u00e1rvore.</p>"},{"location":"random-forest/main/#features-e-target","title":"Features e target","text":"<ul> <li>features (X): <code>AcademicStage</code>, <code>PeerPressure</code>, <code>HomePressure</code>, <code>StudyEnv</code>, <code>Strategy</code>, <code>BadHabits</code>, <code>AcademicComp</code></li> <li>target (y): <code>Stress</code> (1 a 5)</li> </ul>"},{"location":"random-forest/main/#divisao-dos-dados","title":"Divis\u00e3o dos Dados","text":"<p>80% dos registros foram separados para treino e 20% para teste.  </p>"},{"location":"random-forest/main/#binarizacao","title":"Binariza\u00e7\u00e3o","text":"<p>Aproveitei o modelo KNN feito anteriormente e mantive a binariza\u00e7\u00e3o do target neste modelo. (niveis de estresse menores ou iguais a 3 s\u00e3o classificados como \"baixo\" e maiores que 3 como \"alto\"), por\u00e9m ap\u00f3s rodar o modelo, acabou resultando num overfitting (97% de acur\u00e1cia), assim, a binariza\u00e7\u00e3o foi revertida.</p>"},{"location":"random-forest/main/#treinamento-do-modelo","title":"Treinamento do Modelo","text":"random forest code <pre><code>import pandas as pd\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Carregar base\ndf = pd.read_csv(\"https://raw.githubusercontent.com/tigasparzin/Machine-Learning/refs/heads/main/data/StressExp.csv\")\n\ny = (df[\"Stress\"])\n\n# Features fixas da base\nX = df.drop(columns=[\"Timestamp\", \"Stress\"])\nX = pd.get_dummies(\n    X,\n    columns=[\"AcademicStage\", \"StudyEnv\", \"Strategy\", \"BadHabits\"],\n    drop_first=False\n)\n\n# Split estratificado\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\n# Random Forest\nrf = RandomForestClassifier(\n    n_estimators=100,\n    max_depth=5,\n    max_features='sqrt',\n    random_state=42\n)\nrf.fit(X_train, y_train)\n\n# Avalia\u00e7\u00e3o\npred = rf.predict(X_test)\nprint(f\"Accuracy: {accuracy_score(y_test, pred):.2f}\")\nprint()\n\n# Import\u00e2ncias (vetor)\nprint(\"Feature Importances:\", rf.feature_importances_)\n</code></pre>"},{"location":"random-forest/main/#avaliacao-do-modelo","title":"Avalia\u00e7\u00e3o do Modelo","text":"<p>No modelo Random Forest, a acur\u00e1cia foi de ~0.62 .  </p> avaliacao do modelocode <p>Accuracy: 0.62                precision    recall  f1-score   support             1      1.000     0.727     0.842        11            2      0.818     0.818     0.818        11            3      0.438     0.636     0.519        11            4      0.571     0.333     0.421        12            5      0.500     0.636     0.560        11      accuracy                          0.625        56    macro avg      0.665     0.630     0.632        56 weighted avg      0.664     0.625     0.628        56   2025-12-05T14:06:29.001149 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/   Top 10 features: AcademicComp: 0.232 HomePressure: 0.179 BadHabits: 0.177 PeerPressure: 0.149 StudyEnv: 0.092 AcademicStage: 0.089 Strategy: 0.081 </p> <pre><code>import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom io import StringIO\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\nfrom sklearn.ensemble import RandomForestClassifier\n\ndf = pd.read_csv('https://raw.githubusercontent.com/tigasparzin/Machine-Learning/refs/heads/main/data/StressExp.csv')\n\nif 'Timestamp' in df.columns:\n    df = df.drop(columns=['Timestamp'])\n\nX = df[['AcademicStage','PeerPressure','HomePressure','StudyEnv','Strategy','BadHabits','AcademicComp']].copy()\ny = df['Stress'].astype(int)  # sem binariza\u00e7\u00e3o (1..5)\n\nX_train, X_test, y_train, y_test = train_test_split(\n    X, y, test_size=0.2, random_state=42, stratify=y\n)\n\nif X_train['StudyEnv'].isna().any() or X_test['StudyEnv'].isna().any():\n    mode_env = X_train['StudyEnv'].mode().iloc[0]\n    X_train['StudyEnv'] = X_train['StudyEnv'].fillna(mode_env)\n    X_test['StudyEnv']  = X_test['StudyEnv'].fillna(mode_env)\n\ncat_cols = ['AcademicStage','StudyEnv','Strategy','BadHabits']\nencoders = {}\nfor col in cat_cols:\n    le = LabelEncoder()\n    X_train[col] = le.fit_transform(X_train[col].astype(str))\n    X_test[col] = X_test[col].astype(str).where(X_test[col].astype(str).isin(le.classes_), le.classes_[0])\n    import numpy as _np\n    le.classes_ = _np.unique(_np.concatenate([le.classes_, X_test[col].unique()]))\n    X_test[col] = le.transform(X_test[col])\n    encoders[col] = le\n\nclf = RandomForestClassifier(\n    n_estimators=300,\n    max_depth=5,\n    max_features='sqrt',\n    random_state=42,\n    n_jobs=-1\n)\nclf.fit(X_train, y_train)\ny_pred = clf.predict(X_test)\n\nprint(f\"Accuracy: {(y_pred == y_test).mean():.2f}\\n\")\nprint(classification_report(y_test, y_pred, digits=3))\n\nlabels = np.sort(df['Stress'].unique())\ncm = confusion_matrix(y_test, y_pred, labels=labels)\nfig, ax = plt.subplots(figsize=(7, 5))\nConfusionMatrixDisplay(cm, display_labels=labels).plot(\n    ax=ax, cmap=plt.cm.Blues, values_format=\"d\", colorbar=False\n)\nax.set_title(\"Matriz de Confus\u00e3o - RF (5 classes)\")\nax.set_xlabel(\"Previsto\"); ax.set_ylabel(\"Real\")\nbuf = StringIO(); plt.savefig(buf, format=\"svg\", transparent=True, bbox_inches=\"tight\")\nprint(buf.getvalue()); plt.close(fig)\n\nfeat_names = X_train.columns.to_numpy()\nimportances = clf.feature_importances_\ntop_idx = np.argsort(importances)[::-1][:10]\nprint(\"Top 10 features:\")\nfor i in top_idx:\n    print(f\"{feat_names[i]}: {importances[i]:.3f}\")\n</code></pre>"},{"location":"random-forest/main/#conclusao","title":"Conclus\u00e3o","text":"<ul> <li>Analisando nossa matriz de confus\u00e3o, \u00e9 perceptivel que o modelo teve desempenho mediano (Accuracy \u2248 0,63; Macro-F1 \u2248 0,63) com confus\u00e3o forte entre n\u00edveis altos (4\u21945). Bom em 1\u20132, fraco no nivel 4.</li> <li>A informa\u00e7\u00e3o anterior explica bem o por que, em testes anteriores, quando utilizei apenas: niveis baixos (1,2 e 3) e niveis altos (4 e 5), acabei caindo em overfitting, visto que o modelo causa confus\u00e3o entre niveis maiores.</li> <li> <p>Top features: AcademicComp (0,232) &gt; HomePressure (0,179) &gt; BadHabits (0,177) &gt; PeerPressure (0,149) &gt; StudyEnv/Strategy, ou seja, o modelo propoe que os maiores causadores de estresse entre alunos, s\u00e3o: competitividade, pressao sofrida pelos familiares, habitos ruins (beber/fumar), pressao sofrida pelos amigos, tendo por ultimo ambiente de estudo e estrategia para lidar com estresse.</p> </li> <li> <p>Pensando em ideias para deixar o modelo balanceado, imagino que a melhor decis\u00e3o seria criar 3 niveis: Alto(4 e 5), medio (3) e baixo (1 e 2), ou ent\u00e3o distribuir manualmente os pesos, fazendo com que erros no nivel 4 sejam mais penalizados.</p> </li> </ul>"},{"location":"roteiro4/main/","title":"Main","text":"<p>Se chegou aqui, \u00e9 porque voc\u00ea est\u00e1 interessado em saber mais. Logo, de brinde, como rodar um c\u00f3digo <code>Python</code> aqui.</p> 2025-12-05T14:06:29.244972 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ 2025-12-05T14:06:30.618054 image/svg+xml Matplotlib v3.10.7, https://matplotlib.org/ <p>Markdown-exec \u00e9 uma extens\u00e3o do Markdown que permite executar c\u00f3digo Python diretamente no Markdown. Isso \u00e9 \u00fatil para gerar resultados din\u00e2micos ou executar scripts de forma interativa.</p>"}]}